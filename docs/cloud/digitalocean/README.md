
## Setting up Kubernetes in DigitalOcean

Following instructions are about to show you how to use `pharmer` to create, delete, upgrade and scale up or down a
kubernetes cluster in DigitalOcean. Pharmer uses ubuntu 16.04 image as default.

### Installation

```bash
$ go get github.com/appscode/pharmer

```

### Credentials
Get an access token by following the [guide](https://www.digitalocean.com/community/tutorials/how-to-use-the-digitalocean-api-v2#how-to-generate-a-personal-access-token) and pass to it pharmer.

```bash
$ pharmer create credential do
Choose a Cloud provider: DigitalOcean
Personal Access Token
****************************
```
This command creates following yaml file.
```yaml
apiVersion: v1alpha1
kind: Credential
metadata:
  creationTimestamp: 2017-10-03T05:13:07Z
  name: do
spec:
  data:
    token: abcdefghijklmnopqrstuvwxyzabcdefghijklmnopqrstuvwxyz
  provider: DigitalOcean
```
Here,

 * `spec.data.token` is the access token that retrieved from digitalocean.

To modify existing credential you need to run following command

```bash
$ pharmer get credentials
Name
do           DigitalOcean   token=*****
$ pharmer edit credential do
```

### Cluster

#### Creating

Following command is used to create a cluster.

```bash
$ pharmer create cluster d1 \
	--v=5 \
	--provider=digitalocean \
	--zone=nyc3 \
	--nodes=2gb=1 \
	--credential-uid=do \
	--kubernetes-version=1.8.0
```
If you want to use specific version of `kubelet` and  `kubeadm` then you can pass those flag too.
```bash
--kubelet-version='1.8.0' --kubeadm-version='1.8.0'
```

Pharmer uses `calico` as pod network. To change the default network provider to `flannel` you can pass
 `--networking=flannel` flag.

If you are using local file system as a storage engine, the directory structure of the cluster is-

```bash
~/.pharmer/store.d/clusters/
        |-- d1
        |    |__ nodegroups
        |    |       |__ master.json
        |    |       |
        |    |       |__ 2gb-pool.json
        |    |
        |    |--- pki
        |    |     |__ ca.crt
        |    |     |
        |    |     |__ ca.key
        |    |     |
        |    |     |__ front-proxy-ca.crt
        |    |     |
        |    |     |__ fron-proxy-ca.key
        |    |
        |    |__ ssh
        |          |__ id_d1-fpw40n
        |          |
        |          |__ id_f1-fpw40n.pub
        |
        |__ d1.json
```

You can verify the cluster configuration file using following command. You can also modify this file according to you choice.
```bash
$ cat ~/.pharmer/store.d/clusters/d1.json
```

```yaml
$ pharmer get cluster d1 -o yaml

apiVersion: v1alpha1
kind: Cluster
metadata:
  creationTimestamp: 2017-11-10T11:26:23Z
  generation: 1510313183635265805
  name: d1
  uid: ACID-K8S-C-v4ec7ho3if3tt5p
spec:
  api:
    advertiseAddress: ""
    bindPort: 6443
  apiServerExtraArgs:
    kubelet-preferred-address-types: InternalIP,ExternalIP
  authorizationModes:
  - Node
  - RBAC
  caCertName: ca
  cloud:
    cloudProvider: digitalocean
    instanceImage: ubuntu-16-04-x64
    region: nyc3
    zone: nyc3
  credentialName: do
  frontProxyCACertName: front-proxy-ca
  kubernetesVersion: v1.8.0
  networking:
    dnsDomain: cluster.local
    networkProvider: calico
    podSubnet: 192.168.0.0/16
    serviceSubnet: 10.96.0.0/12
status:
  cloud: {}
  phase: Pending
  sshKeyExternalID: d1-ssddan
```
Here,

* `metadata.name` refers the cluster name, which should be unique within your cluster list.
* `metadata.uid` is a unique ACID, which is generated by pharmer
* `spec.cloud` specifies the cloud provider information. pharmer uses `ubuntu-16-04-x64` image by default. don't change the instance images, otherwise cluster may not be working.
* `spec.api.bindPort` is the api server port.
* `spec.networking` specifies the network information of the cluster
    * `networkProvider`: by default it is `calico`. It can be modified by `flannel`.
    * `podSubnet`: in order for network policy to work correctly this field is needed. For flannel it will be `10.244.0.0/16`
* `spec.kubernetesVersion` is the cluster server version. It can be modified.
* `spec.credentialName` is the credential name which is provider during cluster creation command.
* `spec.apiServerExtraArgs` specifies which value will be forwarded to apiserver during cluster installation.
* `spec.authorizationMode` refers the cluster authorization mode
* `status.phase` may be `Pending`, `Ready`, `Deleting`, `Deleted`, `Upgrading` depending on current cluster status.
* `status.sshKeyExternalID` shows which ssh key added to cluster instance.

In `nodegroups` directory you can find the node's information. You can also modify those file accordingly.

```yaml
$ pharmer get ng 2gb-pool -k d1 -o yaml

apiVersion: v1alpha1
kind: NodeGroup
metadata:
  clusterName: d1
  creationTimestamp: 2017-11-10T11:26:24Z
  labels:
    node-role.kubernetes.io/node: ""
  name: 2gb-pool
  uid: ACID-K8S-C-bfpyywjyjjolvds
spec:
  nodes: 1
  template:
    spec:
      sku: 2gb
status:
  nodes: 0
```
Here,
* `metadata.name` refers the node group name, which is unique within a cluster.
* `metadata.labels` specifies the label of the nodegroup, which will be add to all nodes of following node group.
    * For master label will be `"node-role.kubernetes.io/master": ""`
    * For node label will be like `"node-role.kubernetes.io/node": ""`
* `metadata.clusterName` indicates the cluster, which has this node group.
* `spec.nodes` shows the number of nodes for this following group.
* `spec.template.sku` refers the size of the machine
* `status.node` shows the number of nodes that are really present on the current cluster

If everything looks ok you are good to run:
```bash
$ pharmer apply d1 --v=3
```

After finishing cluster bootstrap process, the cluster status phase will be `Ready`.
```yaml
kind: Cluster
metadata:
  creationTimestamp: 2017-11-10T11:26:23Z
  generation: 1510313183635265805
  name: d1
  uid: ACID-K8S-C-v4ec7ho3if3tt5p
spec:
  api:
    advertiseAddress: ""
    bindPort: 6443
  caCertName: ca
  cloud:
    cloudProvider: digitalocean
    instanceImage: ubuntu-16-04-x64
    region: nyc3
    zone: nyc3
  credentialName: do
  frontProxyCACertName: front-proxy-ca
  kubernetesVersion: v1.8.0
  networking:
    networkProvider: calico
    nonMasqueradeCIDR: 10.0.0.0/8
status:
  apiServer:
  - address: 10.132.70.110
    type: InternalIP
  - address: 159.203.122.109
    type: ExternalIP
  cloud: {}
  phase: Ready
  sshKeyExternalID: d1-ssddan
```
Here,
* `status.apiServer` contains the ip addresses of cluster. Order of the addresses are `HostName`, `InternalIP`, `ExternalIP`


You can use the cluster from your local machine by running

```bash
$ pharmer use cluster d1
```


#### Scaling

In terms of scaling a cluster there are two scenarios. Either you can scale up or down existing node groups or you can add a new nodegroup.

##### Scenario 1:

To update an existing node groups (increment or decrement the number of node) following command will help:

```yaml
$ pharmer edit nodegroup 2gb-pool -k d1

# Please edit the object below. Lines beginning with a '#' will be ignored,
# and an empty file will abort the edit. If an error occurs while saving this file will be
# reopened with the relevant failures.
#
apiVersion: v1alpha1
kind: NodeGroup
metadata:
  clusterName: d1
  creationTimestamp: 2017-11-10T11:26:24Z
  labels:
    node-role.kubernetes.io/node: ""
  name: 2gb-pool
  uid: ACID-K8S-C-bfpyywjyjjolvds
spec:
  nodes: 2
  template:
    spec:
      sku: 2gb
status:
  nodes: 1
```

Here modify the `node` number under `spec` field to update certain node group.

If you want to delete the nodegroup  set the number of node is 0.


##### Scenario 2:

To add a new node group run following command:

```yaml
$ pharmer create ng --nodes=4gb=2 -k d1

apiVersion: v1alpha1
kind: NodeGroup
metadata:
  clusterName: d1
  creationTimestamp: 2017-11-10T11:26:24Z
  labels:
    node-role.kubernetes.io/node: ""
  name: 4gb-pool
  uid: ACID-K8S-C-bfpyywjyjjolvdjk
spec:
  nodes: 2
  template:
    spec:
      sku: 4gb
status:
  nodes: 0
```


If you want to delete the node group, run

```yaml
$ pharmer delete ng 2gb-pool -k d1
apiVersion: v1alpha1
kind: NodeGroup
metadata:
  clusterName: d1
  creationTimestamp: 2017-11-10T11:26:24Z
  deletionTimestamp: 2017-11-10T12:47:41Z
  labels:
    node-role.kubernetes.io/node: ""
  name: 2gb-pool
  uid: ACID-K8S-C-bfpyywjyjjolvds
spec:
  nodes: 1
  template:
    spec:
      sku: 2gb
status:
  nodes: 1

```
Here,
* `metadata.deletionTimestamp` will appear if node group deleted command was run

After scaling node groups you need to run:

```bash
$ pharmer apply d1 --v=3
```

#### Upgrading

Pharmer can upgrade a cluster(such as, from 1.7 to 1.8) by using following command.

```bash
$ pharmer edit cluster d1 --kubernetes-version=v1.8.1
```
The other way to to upgrade cluster is edit cluster and manually update ta kubernetes version.

```yaml
apiVersion: v1alpha1
kind: Cluster
metadata:
  creationTimestamp: 2017-11-10T11:26:23Z
  generation: 1510313183635265805
  name: d1
  uid: ACID-K8S-C-v4ec7ho3if3tt5p
spec:
  api:
    advertiseAddress: ""
    bindPort: 6443
  caCertName: ca
  cloud:
    cloudProvider: digitalocean
    instanceImage: ubuntu-16-04-x64
    region: nyc3
    zone: nyc3
  credentialName: do
  frontProxyCACertName: front-proxy-ca
  kubernetesVersion: v1.8.1
  networking:
    networkProvider: calico
    nonMasqueradeCIDR: 10.0.0.0/8
status:
  apiServer:
  - address: 10.132.70.110
    type: InternalIP
  - address: 159.203.122.109
    type: ExternalIP
  cloud: {}
  phase: Upgrading
  sshKeyExternalID: d1-ssddan
```

After upgrading cluster run:

```bash
$ pharmer apply d1 --v=3
```

#### Deleting

To delete a cluster run:

```yaml
$ pharmer delete cluster c1

apiVersion: v1alpha1
kind: Cluster
metadata:
  creationTimestamp: 2017-10-03T05:41:02Z
  deletionTimestamp: 2017-10-03T06:14:29Z
  generation: 1507009262665292092
  name: do1
  uid: ACID-K8S-C-hgdrgjxtzebgpa4
spec:
  api:
    advertiseAddress: ""
    bindPort: 6443
  caCertName: ca
  cloud:
    cloudProvider: digitalocean
    instanceImage: ubuntu-16-04-x64
    region: nyc3
    zone: nyc3
  credentialName: do
  frontProxyCACertName: front-proxy-ca
  kubernetesVersion: v1.8.1
  networking:
    networkProvider: calico
    nonMasqueradeCIDR: 10.0.0.0/8
status:
  apiServer:
  - address: ""
    type: ExternalIP
  - address: ""
    type: InternalIP
  cloud: {}
  phase: Deleting
  sshKeyExternalID: d1-ssddan
```
Here,
* `metadata.deletionTimestamp` is set when cluster deletion command was applied.

After deleting cluster run:

```bash
$ pharmer apply c1 --v=3
```
